{"ast":null,"code":"var _jsxFileName = \"/home/dolan/Downloads/DaveDotCom_/src/screens/ProjectsScreen.js\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nconst ProjectsScreen = () => {\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: /*#__PURE__*/_jsxDEV(\"div\", {\n      children: [/*#__PURE__*/_jsxDEV(\"h1\", {\n        className: \"custom-subTitle\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 7,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        children: /*#__PURE__*/_jsxDEV(\"h1\", {\n          children: \"Welcome to Projects\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 9,\n          columnNumber: 9\n        }, this)\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 8,\n        columnNumber: 5\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        children: /*#__PURE__*/_jsxDEV(\"h2\", {\n          children: \"Here is a list of some things that I've worked on!\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 11,\n          columnNumber: 14\n        }, this)\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 11,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        children: /*#__PURE__*/_jsxDEV(\"h3\", {\n          children: \"My Github: https://github.com/DavidHostler\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 13,\n          columnNumber: 14\n        }, this)\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 13,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        children: /*#__PURE__*/_jsxDEV(\"h2\", {\n          children: \"Machine Learning Related Projects\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 15,\n          columnNumber: 14\n        }, this)\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 15,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"h3\", {\n        children: \"Here are some examples of ML projects that I've created in 2020, 2021:\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 16,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"h3\", {\n        children: \"\\\"Milk\\\" (it's a weird name I know, but some people like a nice glass of Milk now and then). This is a super resolution generative adversarial network that  receives an image of a given size, and uses deep learning to \\\"hallucinate\\\" a more high resolution version of that image.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 21,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        children: \"https://github.com/DavidHostler/Milk\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 27,\n        columnNumber: 13\n      }, this), /*#__PURE__*/_jsxDEV(\"h3\", {\n        children: \"This is a little research project I worked on briefly in late 2020 and early 2021. I had volunteered to help some grad students in the University of Toronto Scarborough materials science research project with implementing a single hidden-layer neural network in order to model high-precision Gaussian functions given a single input value. The idea is that if a given element or compound has a known excitation energy known to a certain accuracy, then we could improve this accuracy by using a neural network to approximate the Gaussian distribution function centred around this excitation energy eigenvalue. The results were that the required neural architecture was insufficient for such a desired result, since training the neural network on successive eigenvalue training data had the effect of causing the model to \\\"unlearn\\\" anything it knew of previous eigenvalue distributions. Therefore, I posit that the only way to implement this method successfully would be to ascribe to the model an attention window- e.g. RNN's, LSTM's or preferably Transformers. These models were deemed too complicated for the desired architecture and so they decided to implement the energy distribution functions directly by hard-coding the distribution function. https://github.com/DavidHostler/Pytorch-Gaussian-NN\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 29,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        children: \"DRACO\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 52,\n        columnNumber: 13\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        children: \" https://github.com/DavidHostler/Draco \"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 53,\n        columnNumber: 12\n      }, this), /*#__PURE__*/_jsxDEV(\"h3\", {\n        children: \"This one is a favorite for a couple of reasons. I was attempting to implement a Reinforcement Learning agent using a technique called Deep Deterministic Policy Gradients or DDPG for short. I wanted to maximize the speed of my agent as well. Python is known to run about ~ 20 times more slowly than C/C++, so I figured that I'd implement my solution in C++ using my current understanding of the Python code at the time. In doing so,  I ran into a few build issues with the Tensorflow C API and figured that since DDPG only uses deep hidden layers (i.e. linear transformations of the form Ax + b = y, where A is a matrix a.k.a. \\\"weights\\\"\\\", x is the input tensor, b is the bias)\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 54,\n        columnNumber: 9\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 6,\n      columnNumber: 5\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 5,\n    columnNumber: 9\n  }, this);\n};\n\n_c = ProjectsScreen;\nexport default ProjectsScreen;\n\nvar _c;\n\n$RefreshReg$(_c, \"ProjectsScreen\");","map":{"version":3,"sources":["/home/dolan/Downloads/DaveDotCom_/src/screens/ProjectsScreen.js"],"names":["ProjectsScreen"],"mappings":";;;AAEA,MAAMA,cAAc,GAAG,MAAM;AACzB,sBACI;AAAA,2BACJ;AAAA,8BACI;AAAI,QAAA,SAAS,EAAC;AAAd;AAAA;AAAA;AAAA;AAAA,cADJ,eAEA;AAAA,+BACI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AADJ;AAAA;AAAA;AAAA;AAAA,cAFA,eAKI;AAAA,+BAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAL;AAAA;AAAA;AAAA;AAAA,cALJ,eAOI;AAAA,+BAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAL;AAAA;AAAA;AAAA;AAAA,cAPJ,eASI;AAAA,+BAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAL;AAAA;AAAA;AAAA;AAAA,cATJ,eAUI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAVJ,eAeI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAfJ,eAqBQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cArBR,eAuBI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAvBJ,eA8CQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cA9CR,eA+CO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cA/CP,eAgDI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAhDJ;AAAA;AAAA;AAAA;AAAA;AAAA;AADI;AAAA;AAAA;AAAA;AAAA,UADJ;AAoEH,CArED;;KAAMA,c;AAuEN,eAAeA,cAAf","sourcesContent":["\n\nconst ProjectsScreen = () => {\n    return(\n        <div >\n    <div>\n        <h1 className=\"custom-subTitle\"></h1>\n    <div>\n        <h1>Welcome to Projects</h1>\n    </div>\n        <div><h2>Here is a list of some things that I've worked on!</h2></div>\n        \n        <div><h3>My Github: https://github.com/DavidHostler</h3></div>\n\n        <div><h2>Machine Learning Related Projects</h2></div>\n        <h3>Here are some examples of ML projects that I've created \n            in 2020, 2021:\n        \n        </h3>\n   \n        <h3>\n            \"Milk\" (it's a weird name I know, but some people like a nice glass of Milk now and then).\n            This is a super resolution generative adversarial network that  receives an image of a given\n            size, and uses deep learning to \"hallucinate\" a more high resolution version of that image.            \n            \n        </h3>\n            <div>https://github.com/DavidHostler/Milk</div>\n\n        <h3>\n\n            This is a little research project I worked on briefly in late 2020 and early 2021.\n            I had volunteered to help some grad students in the University of Toronto Scarborough \n            materials science research project with implementing a single hidden-layer neural network\n            in order to model high-precision Gaussian functions given a single input value.\n\n            The idea is that if a given element or compound has a known excitation energy known to a \n            certain accuracy, then we could improve this accuracy by using a neural network to approximate\n            the Gaussian distribution function centred around this excitation energy eigenvalue.\n\n            The results were that the required neural architecture was insufficient for such a desired result,\n            since training the neural network on successive eigenvalue training data had the effect of causing the \n            model to \"unlearn\" anything it knew of previous eigenvalue distributions.\n            Therefore, I posit that the only way to implement this method successfully would be to ascribe to the\n            model an attention window- e.g. RNN's, LSTM's or preferably Transformers.\n\n            These models were deemed too complicated for the desired architecture and so they decided to implement\n            the energy distribution functions directly by hard-coding the distribution function.\n\n            https://github.com/DavidHostler/Pytorch-Gaussian-NN\n        </h3>\n\n            <div>DRACO</div>\n           <div> https://github.com/DavidHostler/Draco </div>\n        <h3>\n            This one is a favorite for a couple of reasons. I was attempting to implement \n            a Reinforcement Learning agent using a technique called Deep Deterministic Policy Gradients\n            or DDPG for short. I wanted to maximize the speed of my agent as well.\n            \n            Python is known to run about ~ 20 times more slowly than C/C++, \n            so I figured that I'd implement my solution in C++ using my current understanding \n            of the Python code at the time.\n\n            In doing so,  I ran into a few build issues with the Tensorflow C API and figured that\n            since DDPG only uses deep hidden layers (i.e. linear transformations of the form \n            Ax + b = y, where A is a matrix a.k.a. \"weights\"\", x is the input tensor, b is the bias)\n\n        </h3>\n    </div>\n    </div>\n\n    )\n}\n\nexport default ProjectsScreen;"]},"metadata":{},"sourceType":"module"}