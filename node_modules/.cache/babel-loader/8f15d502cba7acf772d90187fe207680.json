{"ast":null,"code":"var _jsxFileName = \"/home/dolan/Downloads/DaveDotCom_/src/screens/ProjectsScreen.js\";\nimport classes from './css/ProjectsScreen.module.css';\nimport ProjectData from './data/ProjectData';\nimport { Component } from 'react';\nimport { render } from '@testing-library/react'; //Declare the data to be presented!\n\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nvar milk = new ProjectData('Milk', 'https://github.com/DavidHostler/Milk', 'Milk (it is a weird name I know, but some people like a nice glass of Milk now and then). This is a super resolution generative adversarial network that receives an image of a given size, and uses deep learning to \"hallucinate\" a more high resolution version of that image.');\nvar gauss = new ProjectData('Gaussian', 'https://github.com/DavidHostler/Pytorch-Gaussian-NN', 'This is a little research project I worked on briefly in late 2020 and early 2021. I had volunteered to help some grad students in the University of Toronto Scarborough materials science research project with implementing a single hidden-layer neural network in order to model high-precision Gaussian functions given a single input value. The idea is that if a given element or compound has a known excitation energy known to a certain accuracy, then we could improve this accuracy by using a neural network to approximate the Gaussian distribution function centred around this excitation energy eigenvalue. The results were that the required neural architecture was insufficient for such a desired result, since training the neural network on successive eigenvalue training data had the effect of causing the model to \"unlearn\" anything it knew of previous eigenvalue distributions. Therefore, I posit that the only way to implement this method successfully would be to ascribe to the model an attention window- e.g. RNNs, LSTMs or preferably Transformers. These models were deemed too complicated for the desired architecture and so they decided to implement the energy distribution functions directly by hard-coding the distribution function.');\nvar draco = new ProjectData('Draco', 'https://github.com/DavidHostler/Draco', 'This one is a favorite for a couple of reasons. I was attempting to implement a Reinforcement Learning agent using a technique called Deep Deterministic Policy Gradients or DDPG for short. I wanted to maximize the speed of my agent as well. Python is known to run about ~ 20 times more slowly than C/C++, so I figured that I would implement my solution in C++ using my current understanding of the Python code at the time. In doing so, I ran into a few build issues with the Tensorflow C API and figured that since DDPG only uses deep hidden layers (i.e. linear transformations of the form Ax + b = y, where A is a matrix a.k.a. \"weights\"\", x is the input tensor, b is the bias) This project allowed me to play around with a super fast RL simulation and learn more about the direct behaviour of deep learning models from a mathematical point of view, as I had to hard-code the linear transformations and take the derivatives of activation functions numerically. If using this model, depending on the user architecture you might want to consider implementing a Big Float datatype to prevent Nan values as weights, biases or gradients.');\n\nfunction ProjectDetails(props) {\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"center_all\",\n    children: [/*#__PURE__*/_jsxDEV(\"p\", {\n      children: props.title\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 29,\n      columnNumber: 9\n    }, this), /*#__PURE__*/_jsxDEV(\"h1\", {\n      children: props.link\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 30,\n      columnNumber: 9\n    }, this), /*#__PURE__*/_jsxDEV(\"h3\", {\n      children: props.body\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 31,\n      columnNumber: 9\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 28,\n    columnNumber: 9\n  }, this);\n}\n\n_c = ProjectDetails;\n\nfunction ProjectsScreen() {\n  function handleClick(e) {\n    e.preventDefault();\n    console.log('The link was clicked.');\n  }\n\n  return /*#__PURE__*/_jsxDEV(\"a\", {\n    href: \"#\",\n    onClick: handleClick,\n    children: \"Click me\"\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 42,\n    columnNumber: 9\n  }, this); // return(\n  // <div>\n  //     <button>Gauss</button>\n  //     <ProjectDetails title = {gauss.title}\n  //                     body = {gauss.body}\n  //                     >\n  //     </ProjectDetails>\n  // </div>\n  // )\n}\n\n_c2 = ProjectsScreen;\nexport default ProjectsScreen; // const ProjectsScreen = () => {\n//     return(\n//         <div >\n//     <div>\n//         <h1 className=\"custom-subTitle\"></h1>\n//     <div>\n//         <h1>Welcome to Projects</h1>\n//     </div>\n//         <div><h2>Here is a list of some things that I've worked on!</h2></div>\n//         <div><h5>My Github: https://github.com/DavidHostler</h5></div>\n//         <div><h2>Machine Learning Related Projects</h2></div>\n//         <h5>Here are some examples of ML projects that I've created \n//             in 2020, 2021:\n//         </h5>\n//         <h5>\n//             \"Milk\" (it's a weird name I know, but some people like a nice glass of Milk now and then).\n//             This is a super resolution generative adversarial network that  receives an image of a given\n//             size, and uses deep learning to \"hallucinate\" a more high resolution version of that image.            \n//         </h5>\n//             <div>\n//                 <h5>\n//                 https://github.com/DavidHostler/Milk\n//                 </h5>\n//             </div>\n//             <div><h5>\n//             https://github.com/DavidHostler/Pytorch-Gaussian-NN\n//                 </h5></div>\n//         <h5>\n//             This is a little research project I worked on briefly in late 2020 and early 2021.\n//             I had volunteered to help some grad students in the University of Toronto Scarborough \n//             materials science research project with implementing a single hidden-layer neural network\n//             in order to model high-precision Gaussian functions given a single input value.\n//             The idea is that if a given element or compound has a known excitation energy known to a \n//             certain accuracy, then we could improve this accuracy by using a neural network to approximate\n//             the Gaussian distribution function centred around this excitation energy eigenvalue.\n//             The results were that the required neural architecture was insufficient for such a desired result,\n//             since training the neural network on successive eigenvalue training data had the effect of causing the \n//             model to \"unlearn\" anything it knew of previous eigenvalue distributions.\n//             Therefore, I posit that the only way to implement this method successfully would be to ascribe to the\n//             model an attention window- e.g. RNN's, LSTM's or preferably Transformers.\n//             These models were deemed too complicated for the desired architecture and so they decided to implement\n//             the energy distribution functions directly by hard-coding the distribution function.\n//         </h5>\n//             <div><h3>DRACO</h3></div>\n//            <div> <h5>https://github.com/DavidHostler/Draco</h5> </div>\n//         <h5>\n//             This one is a favorite for a couple of reasons. I was attempting to implement \n//             a Reinforcement Learning agent using a technique called Deep Deterministic Policy Gradients\n//             or DDPG for short. I wanted to maximize the speed of my agent as well.\n//             Python is known to run about ~ 20 times more slowly than C/C++, \n//             so I figured that I'd implement my solution in C++ using my current understanding \n//             of the Python code at the time.\n//             In doing so,  I ran into a few build issues with the Tensorflow C API and figured that\n//             since DDPG only uses deep hidden layers (i.e. linear transformations of the form \n//             Ax + b = y, where A is a matrix a.k.a. \"weights\"\", x is the input tensor, b is the bias)\n//             This project allowed me to play around with a super fast RL simulation and learn more \n//             about the direct behaviour of deep learning models from a mathematical point of view, \n//             as I had to hard-code the linear transformations and take the derivatives of activation \n//             functions numerically.\n//             If using this model, depending on the user's architecture you might want to consider implementing\n//             a \"Big Float\" datatype to prevent \"Nan\" values as weights, biases or gradients.\n//         </h5>\n//         <div><h2>Web Develpment</h2></div>\n//         <div><h5>https://github.com/DavidHostler/Invinzsible</h5></div>\n//         <h5>\n//         During 2021, I briefly worked as a Fullstack developer for a business \n//         called Invinzsible Inc. With a small team, I implemented many (but not all)\n//         of the website's features using my favorite stack, ReactJS and the Django\n//         Rest Framework.\n//         Using ReactJS, I built a basic layout of page navigation to get from the homse\n//         page to the checkout and inventory screens. Additionally, I implemented a backend\n//         using Django with Python and created three endpoints: Products, Orders, and Cart.\n//         I deployed this basic REST API to Heroku, and used Postman to make sure that various \n//         HTTP requests worked (GET, POST, PUT, and DELETE).\n//         Once the basic CRUD app was working online, I made use of Axios, a very useful web client\n//         for NodeJS, and basic React hooks (useState, useEffect) to interact with JSON data from\n//         the API. This would allow a potential user to view a product, add it to their cart, and \n//         make a purchase of all items in said cart once their shopping trip is satisfactory.\n//         </h5>\n//          <div><h5>\n//              <div>I have developed a ton of other projects related to web and mobile\n//                 fullstack development, some yet to be made public on Github.\n//                 Coming soon, I may post the React-Native chat app code that I've been working on\n//                 for mobile (I was hoping to maybe get a few customers should I complete it!)\n//                 </div>\n//              <div>\n//                 Additionally, I have a few stock projects that I may have had little time to \n//                 complete but that I thought were potential money-makers, including a dating app, \n//                 a cryptocurrency payment service, and maybe a data based fitness app.\n//              </div>\n//              <div>\n//                 The latter I suspect will be difficult to monetize as a consequence of human hubris-\n//                 attempting to make accurate recommendations for fitness routines, users would have to give\n//                 honest measurements of their strength and size. The problem with this is that most \n//                 young men will say that they can bench 225 and think that they are 15% bodyfat!\n//              </div>\n//              </h5></div>\n//     </div>\n//     </div>\n//     )\n// }\n// export default ProjectsScreen;\n\nvar _c, _c2;\n\n$RefreshReg$(_c, \"ProjectDetails\");\n$RefreshReg$(_c2, \"ProjectsScreen\");","map":{"version":3,"sources":["/home/dolan/Downloads/DaveDotCom_/src/screens/ProjectsScreen.js"],"names":["classes","ProjectData","Component","render","milk","gauss","draco","ProjectDetails","props","title","link","body","ProjectsScreen","handleClick","e","preventDefault","console","log"],"mappings":";AAAA,OAAOA,OAAP,MAAoB,iCAApB;AACA,OAAOC,WAAP,MAAwB,oBAAxB;AACA,SAASC,SAAT,QAA0B,OAA1B;AACA,SAASC,MAAT,QAAuB,wBAAvB,C,CAEA;;;AACA,IAAIC,IAAI,GAAG,IAAIH,WAAJ,CACP,MADO,EAEP,sCAFO,EAGP,mRAHO,CAAX;AAMA,IAAII,KAAK,GAAG,IAAIJ,WAAJ,CACR,UADQ,EAER,qDAFQ,EAGR,+tCAHQ,CAAZ;AAMA,IAAIK,KAAK,GAAG,IAAIL,WAAJ,CACR,OADQ,EAER,uCAFQ,EAGR,+mCAHQ,CAAZ;;AAOA,SAASM,cAAT,CAAwBC,KAAxB,EAA8B;AAC1B,sBACI;AAAK,IAAA,SAAS,EAAC,YAAf;AAAA,4BACA;AAAA,gBAAIA,KAAK,CAACC;AAAV;AAAA;AAAA;AAAA;AAAA,YADA,eAEA;AAAA,gBAAKD,KAAK,CAACE;AAAX;AAAA;AAAA;AAAA;AAAA,YAFA,eAGA;AAAA,gBAAKF,KAAK,CAACG;AAAX;AAAA;AAAA;AAAA;AAAA,YAHA;AAAA;AAAA;AAAA;AAAA;AAAA,UADJ;AAOH;;KARQJ,c;;AAUT,SAASK,cAAT,GAAyB;AACrB,WAASC,WAAT,CAAqBC,CAArB,EAAwB;AACpBA,IAAAA,CAAC,CAACC,cAAF;AACAC,IAAAA,OAAO,CAACC,GAAR,CAAY,uBAAZ;AACD;;AACD,sBACE;AAAG,IAAA,IAAI,EAAC,GAAR;AAAY,IAAA,OAAO,EAAEJ,WAArB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,UADF,CALmB,CAUrB;AAEA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACH;;MAtBQD,c;AAyBT,eAAeA,cAAf,C,CACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AAGA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AASA;AACA;AACA;AAEA;AACA;AAEA","sourcesContent":["import classes from './css/ProjectsScreen.module.css';\nimport ProjectData from './data/ProjectData';\nimport { Component } from 'react';\nimport { render } from '@testing-library/react';\n\n//Declare the data to be presented!\nvar milk = new ProjectData(\n    'Milk',\n    'https://github.com/DavidHostler/Milk',\n    'Milk (it is a weird name I know, but some people like a nice glass of Milk now and then). This is a super resolution generative adversarial network that receives an image of a given size, and uses deep learning to \"hallucinate\" a more high resolution version of that image.'\n);\n\nvar gauss = new ProjectData(\n    'Gaussian',\n    'https://github.com/DavidHostler/Pytorch-Gaussian-NN',\n    'This is a little research project I worked on briefly in late 2020 and early 2021. I had volunteered to help some grad students in the University of Toronto Scarborough materials science research project with implementing a single hidden-layer neural network in order to model high-precision Gaussian functions given a single input value. The idea is that if a given element or compound has a known excitation energy known to a certain accuracy, then we could improve this accuracy by using a neural network to approximate the Gaussian distribution function centred around this excitation energy eigenvalue. The results were that the required neural architecture was insufficient for such a desired result, since training the neural network on successive eigenvalue training data had the effect of causing the model to \"unlearn\" anything it knew of previous eigenvalue distributions. Therefore, I posit that the only way to implement this method successfully would be to ascribe to the model an attention window- e.g. RNNs, LSTMs or preferably Transformers. These models were deemed too complicated for the desired architecture and so they decided to implement the energy distribution functions directly by hard-coding the distribution function.'\n);\n\nvar draco = new ProjectData(\n    'Draco',\n    'https://github.com/DavidHostler/Draco',\n    'This one is a favorite for a couple of reasons. I was attempting to implement a Reinforcement Learning agent using a technique called Deep Deterministic Policy Gradients or DDPG for short. I wanted to maximize the speed of my agent as well. Python is known to run about ~ 20 times more slowly than C/C++, so I figured that I would implement my solution in C++ using my current understanding of the Python code at the time. In doing so, I ran into a few build issues with the Tensorflow C API and figured that since DDPG only uses deep hidden layers (i.e. linear transformations of the form Ax + b = y, where A is a matrix a.k.a. \"weights\"\", x is the input tensor, b is the bias) This project allowed me to play around with a super fast RL simulation and learn more about the direct behaviour of deep learning models from a mathematical point of view, as I had to hard-code the linear transformations and take the derivatives of activation functions numerically. If using this model, depending on the user architecture you might want to consider implementing a Big Float datatype to prevent Nan values as weights, biases or gradients.'\n);\n\n\nfunction ProjectDetails(props){\n    return(\n        <div className=\"center_all\">\n        <p>{props.title}</p>\n        <h1>{props.link}</h1>\n        <h3>{props.body}</h3>\n        </div>\n    )\n}\n  \nfunction ProjectsScreen(){\n    function handleClick(e) {\n        e.preventDefault();\n        console.log('The link was clicked.');\n      }\n      return (\n        <a href=\"#\" onClick={handleClick}>\n          Click me\n        </a>\n      );\n    // return(\n\n    // <div>\n    //     <button>Gauss</button>\n    //     <ProjectDetails title = {gauss.title}\n    //                     body = {gauss.body}\n    //                     >\n                    \n                    \n    //     </ProjectDetails>\n    // </div>\n    // )\n}\n  \n\nexport default ProjectsScreen;\n// const ProjectsScreen = () => {\n//     return(\n//         <div >\n//     <div>\n//         <h1 className=\"custom-subTitle\"></h1>\n//     <div>\n//         <h1>Welcome to Projects</h1>\n//     </div>\n//         <div><h2>Here is a list of some things that I've worked on!</h2></div>\n        \n//         <div><h5>My Github: https://github.com/DavidHostler</h5></div>\n\n//         <div><h2>Machine Learning Related Projects</h2></div>\n//         <h5>Here are some examples of ML projects that I've created \n//             in 2020, 2021:\n        \n//         </h5>\n   \n//         <h5>\n//             \"Milk\" (it's a weird name I know, but some people like a nice glass of Milk now and then).\n//             This is a super resolution generative adversarial network that  receives an image of a given\n//             size, and uses deep learning to \"hallucinate\" a more high resolution version of that image.            \n            \n//         </h5>\n//             <div>\n//                 <h5>\n//                 https://github.com/DavidHostler/Milk\n//                 </h5>\n//             </div>\n\n//             <div><h5>\n                \n//             https://github.com/DavidHostler/Pytorch-Gaussian-NN\n\n//                 </h5></div>\n//         <h5>\n\n//             This is a little research project I worked on briefly in late 2020 and early 2021.\n//             I had volunteered to help some grad students in the University of Toronto Scarborough \n//             materials science research project with implementing a single hidden-layer neural network\n//             in order to model high-precision Gaussian functions given a single input value.\n\n//             The idea is that if a given element or compound has a known excitation energy known to a \n//             certain accuracy, then we could improve this accuracy by using a neural network to approximate\n//             the Gaussian distribution function centred around this excitation energy eigenvalue.\n\n//             The results were that the required neural architecture was insufficient for such a desired result,\n//             since training the neural network on successive eigenvalue training data had the effect of causing the \n//             model to \"unlearn\" anything it knew of previous eigenvalue distributions.\n//             Therefore, I posit that the only way to implement this method successfully would be to ascribe to the\n//             model an attention window- e.g. RNN's, LSTM's or preferably Transformers.\n\n//             These models were deemed too complicated for the desired architecture and so they decided to implement\n//             the energy distribution functions directly by hard-coding the distribution function.\n\n//         </h5>\n\n//             <div><h3>DRACO</h3></div>\n//            <div> <h5>https://github.com/DavidHostler/Draco</h5> </div>\n//         <h5>\n//             This one is a favorite for a couple of reasons. I was attempting to implement \n//             a Reinforcement Learning agent using a technique called Deep Deterministic Policy Gradients\n//             or DDPG for short. I wanted to maximize the speed of my agent as well.\n            \n//             Python is known to run about ~ 20 times more slowly than C/C++, \n//             so I figured that I'd implement my solution in C++ using my current understanding \n//             of the Python code at the time.\n\n//             In doing so,  I ran into a few build issues with the Tensorflow C API and figured that\n//             since DDPG only uses deep hidden layers (i.e. linear transformations of the form \n//             Ax + b = y, where A is a matrix a.k.a. \"weights\"\", x is the input tensor, b is the bias)\n            \n//             This project allowed me to play around with a super fast RL simulation and learn more \n//             about the direct behaviour of deep learning models from a mathematical point of view, \n//             as I had to hard-code the linear transformations and take the derivatives of activation \n//             functions numerically.\n\n//             If using this model, depending on the user's architecture you might want to consider implementing\n//             a \"Big Float\" datatype to prevent \"Nan\" values as weights, biases or gradients.\n//         </h5>\n\n//         <div><h2>Web Develpment</h2></div>\n\n//         <div><h5>https://github.com/DavidHostler/Invinzsible</h5></div>\n\n        \n//         <h5>\n\n//         During 2021, I briefly worked as a Fullstack developer for a business \n//         called Invinzsible Inc. With a small team, I implemented many (but not all)\n//         of the website's features using my favorite stack, ReactJS and the Django\n//         Rest Framework.\n\n//         Using ReactJS, I built a basic layout of page navigation to get from the homse\n//         page to the checkout and inventory screens. Additionally, I implemented a backend\n//         using Django with Python and created three endpoints: Products, Orders, and Cart.\n//         I deployed this basic REST API to Heroku, and used Postman to make sure that various \n//         HTTP requests worked (GET, POST, PUT, and DELETE).\n        \n//         Once the basic CRUD app was working online, I made use of Axios, a very useful web client\n//         for NodeJS, and basic React hooks (useState, useEffect) to interact with JSON data from\n//         the API. This would allow a potential user to view a product, add it to their cart, and \n//         make a purchase of all items in said cart once their shopping trip is satisfactory.\n\n//         </h5>\n         \n//          <div><h5>\n//              <div>I have developed a ton of other projects related to web and mobile\n//                 fullstack development, some yet to be made public on Github.\n//                 Coming soon, I may post the React-Native chat app code that I've been working on\n//                 for mobile (I was hoping to maybe get a few customers should I complete it!)\n//                 </div>\n//              <div>\n//                 Additionally, I have a few stock projects that I may have had little time to \n//                 complete but that I thought were potential money-makers, including a dating app, \n//                 a cryptocurrency payment service, and maybe a data based fitness app.\n//              </div>\n//              <div>\n//                 The latter I suspect will be difficult to monetize as a consequence of human hubris-\n//                 attempting to make accurate recommendations for fitness routines, users would have to give\n//                 honest measurements of their strength and size. The problem with this is that most \n//                 young men will say that they can bench 225 and think that they are 15% bodyfat!\n//              </div>\n\n\n                \n            \n                \n\n                \n\n//              </h5></div>\n//     </div>\n//     </div>\n\n//     )\n// }\n\n// export default ProjectsScreen;"]},"metadata":{},"sourceType":"module"}